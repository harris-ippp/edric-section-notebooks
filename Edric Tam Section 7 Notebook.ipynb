{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorry previous notebook not yet updated...they are in my broken computer which wouldn't boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Well done on Quiz Today\n",
    "    - apologies for typos for morning section\n",
    "\n",
    "- This week's review (common mistakes and stuff relevant to this assignment)\n",
    "    - This assignment\n",
    "        - seems like many of you have questions ... will try to keep review short and sweet and make Q & A longer today\n",
    "        - beware of style\n",
    "        - REMEMBER ANSWERS.txt\n",
    "        - even if you can't scrape, can use the given csv file for pandas data analysis\n",
    "        - regular expression knowlege is useful for pandas analysis part\n",
    "        \n",
    "    - webscraping demo\n",
    "        - step 1: look at website and see what information you want to scrape\n",
    "        - step 2: look at source code of website and find the unique tags/attributes that contains your information\n",
    "        - step 3: use BeautifulSoup to parse the pages\n",
    "        - step 4: Use BeautifulSoup functions or loops or regular expressions to save the information into useful data structures such as pandas dataframes for further analysis\n",
    "            - easiest way is to store a list of dictionaries, and then use pd.DataFrame() to convert to pandas dataframe format\n",
    "\n",
    "    - Regular Expressions (used in analysis part of assignment)\n",
    "        - Step 1: find out what patterns you want to match for\n",
    "        - Step 2: compile that pattern\n",
    "        - Step 3: feed a string to that pattern to find matches\n",
    "        - Most important regex patterns to know\n",
    "            - * \n",
    "            - d\n",
    "            - +\n",
    "            - ?\n",
    "            - \\\n",
    "        - some useful regex functions:\n",
    "            - findall (don't confuse with BeautifulSoup's find_all)\n",
    "        \n",
    "    - Unicode Encodings\n",
    "        - right after you scrape, turn soup object into utf8 encoding\n",
    "        - should resolve issue\n",
    " \n",
    "- Q&A\n",
    "    - slido.com\n",
    "    - event code R466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example link https://en.wikipedia.org/wiki/List_of_Nobel_laureates\n",
    "\n",
    "### Standard boilerplate\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base = 'https://en.wikipedia.org'\n",
    "path = '/wiki/List_of_Nobel_laureates'\n",
    "\n",
    "response = requests.get(base + path)\n",
    "page = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelList = []\n",
    "for spanTag in page.find_all(\"span\", class_ = \"sortkey\"):\n",
    "    nobelList.append(spanTag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInfo(name, path):\n",
    "    print(path)\n",
    "    base = 'https://en.wikipedia.org'\n",
    "    url = base + path\n",
    "    response = requests.get(base + path)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    birthday = page.find(\"span\", class_=\"bday\")\n",
    "    nationality = page.find(\"td\", class_=\"category\")\n",
    "    bdayText = birthday.text\n",
    "    nationText = nationality.text\n",
    "#     if birthday is None:\n",
    "#         bdayText = None\n",
    "#     else:\n",
    "#         bdayText = birthday.Text\n",
    "#     if nationality is None:\n",
    "#         nationText = None\n",
    "#     else:\n",
    "#         nationText = nationality.Text\n",
    "#     print(bdayText)\n",
    "    return {\"name\":name, \"birthday\": bdayText, \"nationality\": nationText}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobelListDict = []\n",
    "for tag in page.find_all(\"span\", class_ = \"fn\")[0:10]:\n",
    "    print(tag.contents[0].attrs['title'])\n",
    "    name = tag.contents[0].attrs['title']\n",
    "    print(tag.contents[0].attrs['href'])\n",
    "    path = tag.contents[0].attrs['href']\n",
    "    nobelListDict.append(extractInfo(name, str(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nobelListDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "pattern1 = re.compile(\"\\d+\")\n",
    "pattern2 = re.compile(\"\\d\")\n",
    "pattern3 = re.compile(\"\\d?\")\n",
    "pattern4 = re.compile(\"\\d*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1.findall(\"ajkdsjf111\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern2.findall(\"ajkdsjf111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern3.findall(\"ajkdsjf111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern4.findall(\"ajkdsjf111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = chr(40960) + u'abcd' + chr(1972)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.encode('ascii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
